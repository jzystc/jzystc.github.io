---
title: weekly report 2020-10-27
date: 2020-10-27 11:04:14
tags:
    - report
---

## 链路预测与知识图谱补全的关系
知识图谱补全任务是根据知识图谱中的已知三元组预测未知的三元组.
对于知识图谱, 知识图谱补全和链路预测是同一种概念,可以进一步划分成实体预测和关系预测.
1. 实体预测 (entity prediction), 又分为(h,r,?)和(?,r,t), 知识图谱表示学习一般都通过实体预测任务评测模型好坏
2. 关系预测 (relation prediction), 即(h,?,t), 当数据集中的关系种数很少时, 预测难度较低

少样本实体预测任务的目的是希望让模型根据一种新的关系的少量三元组去预测这种关系的其他三元组
TransE学习到的实体嵌入在空间中的相对位置关系就可以理解为两个实体之间的关系, 用于训练实体的相关三元组越多,实体之间相对位置关系(t-h)代表它们之间的关系就越准确.
## TransE和少样本知识图谱补全的区别
### 目标任务不同
+ TransE的任务是学习知识图谱中实体和关系的向量表示,通过预测三元组中的尾实体是什么(h,r,?)来评测向量表示的好坏.
+ 少样本知识图谱补全的任务是已知关系$r$的$n$个三元组中的头尾实体对$\{(h,t)|(h,r,t)\in G\}$. $h,t$的向量已知, $r$的向量未知. 预测其他关于$r$的三元组中的尾实体是什么(h,r,?).

### 数据集不同
1. TransE的验证/测试集中的实体和关系全都包含在训练集中
2. TransE在训练集上训练后得到了所有实体和关系的嵌入
3. 少样本数据集分成训练/验证/测试集和背景知识图谱,训练/验证/测试集的实体嵌入可以通过在背景知识图谱上预训练得到
4. 少样本训练/验证/测试集的关系集合的交集为$\varnothing$,
5. TransE在验证/测试时,分数计算公式$||h+r-t||_2$中的$h,r,t$都是已经训练好的向量.
6. 在少样本任务中,$||h+r-t||_2$中的$h,t$是预训练或随机初始化的向量,$r$则是根据支持集得到的向量.
   
+ 知识图谱表示学习常用数据集
    
    
    | dataset | #relation | #entity | # triple(train/valild/test)    |
    | ------- | --------- | ------- | ------------------------------ |
    | WN11    | 11        | 38696   | 112581    2609    10544        |
    | WN18    | 18        | 40943   | 141442     5000     5000       |
    | FB13    | 13        | 75043   | 316232     5908     23733      |
    | FB15K   | 1345      | 14951   | 483142     50000     59071     |
    | FB1M    | 23382     | 1\*10^6 | 17.5\*10^6    50000     177404 |
    | FB5M    | 1192      | 5385322 | 19193556     5000     59071    |
+ FB15K
  + 训练/验证/测试集之间实体/关系交集数
      
      
    |       | train (e) | valid (e) | test (e) | train (r) | valid (r) | test (r) |
    | ----- | --------- | --------- | -------- | --------- | --------- | -------- |
    | train | 14951     | 13292     | 13584    | 1345      | 916       | 961      |
    | valid |           | 13292     | 12568    |           | 916       | 821      |
    | test  |           |           | 13584    |           |           | 961      |


+ FB13
  + 训练/验证/测试集之间实体/关系交集数
    
    
    |       | train (e) | valid (e) | test (e) | train (r) | valid (r) | test (r) |
    | ----- | --------- | --------- | -------- | --------- | --------- | -------- |
    | train | 75043     | 6158      | 18862    | 13        | 7         | 7        |
    | valid |           | 6158      | 3208     |           | 7         | 7        |
    | test  |           |           | 18862    |           |           | 7        |

+ NELL-One
  + 训练/验证/测试集之间实体/关系交集数
     
     
    |       | train (e) | valid (e) | test (e) | train (r) | valid (r) | test (r) |
    | ----- | --------- | --------- | -------- | --------- | --------- | -------- |
    | train | 6407      | 451       | 847      | 51        | 0         | 0        |
    | valid |           | 712       | 135      |           | 5         | 0        |
    | test  |           |           | 1639     |           |           | 11       |
  + 背景知识图谱与训练/验证/测试集之间实体/关系交集数
背景知识图谱与训练/验证/测试集之间的关系不相交,背景知识图谱中的实体集合包含训练/验证/测试集中的所有实体
```
background train entity 68544 6407 6407
background valid entity 68544 712 712
background test entity 68544 1639 1639
background train relation 291 51 0
background valid relation 291 5 0
background test relation 291 11 0
```
通过以上3个表格可以看出,虽然TransE论文的实验同样是预测尾实体,但是数据集的切分方式与少样本数据集不同. TransE论文的实验效果依赖于训练集得到的实体嵌入和关系嵌入,少样本的实验效果依赖于背景知识图谱得到的实体嵌入.如果去掉背景知识图谱,采用随机初始化的方式进行少样本实验,实验效果依赖于通过对训练集的实体进行finetuning, 然而finetuning对实验效果是否有提升取决于训练集与验证集/测试集中的实体交集的个数,交集越大,效果越好. 在删除训练集中与测试集中的实体交集的条件下,MetaR效果下降得非常明显,但是TransE的结果不受影响,因为TransE不依赖finetuning,直接使用预训练的实体嵌入预测尾实体.


``` 
MetaR 5-shot batch_size=128
删除后 MRR: 0.098      Hits@10: 0.235  Hits@5: 0.153   Hits@1: 0.043
删除前 MRR: 0.189      Hits@10: 0.303  Hits@5: 0.250   Hits@1: 0.113
TransE 5-shot
删除前 MRR: 0.225	Hits@10: 0.389	Hits@5: 0.300	Hits@1: 0.144
删除后 MRR: 0.225	Hits@10: 0.389	Hits@5: 0.300	Hits@1: 0.144
```

## 目前的想法
### 计算分数的方式
+ 融合邻居信息相似度与关系相似度
+ 设n是实体e的邻居的个数,邻居是关系与尾实体的拼接,邻居的聚合方式有2种,第1种是每个邻居乘上其关系对应的tfidf值再求和,第2种是先把邻居中的关系和实体乘上各自的tfidf再拼接,多个邻居再相加求和.
    $$e_{neighbor}=\sum_{i=1}^{n}{w_i}N^{e}_{i}\\w_i=TFIDF(r_i)\\N_i=concat(r_i,t_i) \tag{w1}$$
    $$e_{neighbor}=\sum_{i=1}^{n}{N_i^{e}}\\w_i=TFIDF((r/t)_i)\\N_i=concat(w_{r_i}r_i,w_{t_i}t_i) \tag{w2}$$
+ 综合头实体和尾实体邻居信息的方式有3种
    $$neighbor=concat(h_{neighbor},t_{neighbor}) \tag{n1}$$
    $$neighbor=t_{neighbor}-h_{neighbor}  \tag{n2}$$
    $$neighbor=t_{neighbor}+h_{neighbor}  \tag{n3}$$
+ 最后计算分数的方式有两种,第1种是计算查询集头尾实体与支持集关系的欧式距离,再加上查询集与支持集实体对邻居信息的余弦相似度.第2种是把计算查询集头尾实体与支持集关系的相似度的方法换成余弦相似度.实验结果表明余弦距离效果更好.
    $$score=||h_q+r_s-t_q||_2+cos(query_{neighbor},support_{neighbor}) \tag{s1}$$
    $$score=cos((h_q+r_s),t_q)+cos(query_{neighbor},support_{neighbor}) \tag{s2}$$


| Method   | N-shot | MRR   | Hits@10 | Hits@5 | Hits@1 |
| -------- | ------ | ----- | ------- | ------ | ------ |
| w1+n1+s2 | 5      | 0.150 | 0.210   | 0.182  | 0.108  |
| w2+n1+s2 | 5      | 0.195 | 0.347   | 0.254  | 0.117  |
| w1+n2+s2 | 5      | 0.163 | 0.242   | 0.200  | 0.119  |
| w2+n2+s2 | 5      | 0.195 | 0.345   | 0.256  | 0.123  |
| w1+n3+s2 | 5      | 0.154 | 0.226   | 0.188  | 0.109  |
| w2+n3+s2 | 5      | 0.186 | 0.313   | 0.239  | 0.114  |


比较结果看出同时对邻居中的实体和关系加权效果更好,(尾实体邻居向量-头实体邻居向量)效果更好,使用余弦相似度比欧式距离更好.

5-shot条件下,加入邻居信息的效果差于不加.
1-shot条件下,加入邻居信息的效果好于不加.
```
1-shot
否  MRR: 0.144  Hits@10: 0.235  Hits@5: 0.178   Hits@1: 0.089
是  MRR: 0.150  Hits@10: 0.252  Hits@5: 0.186   Hits@1: 0.106
```

不finetune情况下,TransE效果好于MetaR和GMatching
### 最近的尝试
+ Prototype Network with squared euclidean distance
   
   
   | n-shot | finetune | MRR   | Hits@10 | Hits@5 | Hits@1 |
   | ------ | -------- | ----- | ------- | ------ | ------ |
   | 1      | True     | 0.195 | 0.294   | 0.244  | 0.146  |
   | 5      | True     | 0.210 | 0.352   | 0.278  | 0.145  |

+ GMatching+MetaR 
  ```
  通过GMatching融合邻居信息并计算匹配分数,同时用MetaR计算匹配分数
  score=GMatching_score(qry,spt)+MetaR_score(qry,spt)
  --max_neighbor 50
  --batch_size 128
  ```
    
    
| n-shot | finetune | MRR   | Hits@10 | Hits@5 | Hits@1 |
| ------ | -------- | ----- | ------- | ------ | ------ |
| 1      | True     | 0.188 | 0.295   | 0.240  | 0.129  |
| 1      | False    | 0.178 | 0.272   | 0.222  | 0.133  |
